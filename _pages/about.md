---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a 1st-year Master student of [AIM Lab](http://aim-nercms.whu.edu.cn/) at [National Engineering Research Center for Multimedia Software (国家多媒体软件工程技术研究中心)](http://multimedia.whu.edu.cn/), [Wuhan University (武汉大学)](https://www.whu.edu.cn/), extremely fortunate to be supervised by [Prof. Zheng Wang](https://wangzwhu.github.io/home/). I received my Bachelor's degree from [School of Computer Science (计算机学院)](https://cs.whu.edu.cn/), [Wuhan University (武汉大学)](https://www.whu.edu.cn/).

My research interests primarily lie in the realm of digital humans, with a specific focus on human motion generation. If you are interested, please feel free to email me at [wangrunqi@whu.edu.cn](mailto:wangrunqi@whu.edu.cn).

<a href='https://wangrunqi77.github.io/'>CV<strong></strong></a>

# 🔥 News
<!--- *2024.04*: &nbsp;🎉🎉 One paper is accepted by IJCAI 2024!-->
<!--- *2023.10*: &nbsp;🎉🎉 I win the Freshman Scholarship at Wuhan University!-->

# 📝 Publications 
<!-- -<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2024</div><img src='images/total.png' alt="sym" width="100%"></div></div>-->
<!-- <div class='paper-box-text' markdown="1">-->
<!-- [Expressiveness is Effectiveness: Self-supervised Fashion-aware CLIP for Video-to-Shop Retrieval](https://likaitian.github.io/)-->

**Likai Tian**, Zhengwei Yang, Zechao Hu, Li Hao, Yifang Yin, Zheng Wang

<!-- - This work highlights the significance of salient frames in the Video-to-Shop Retrieval task and introduce fashion expressiveness to determine the saliency of each video frame. -->
<!--- This work proposes a Self-supervised Fashion-aware Contrastive Language-Image Pre-training (SF-CLIP) framework, which expands the ability of CLIP with a strong sense of fashion expressiveness for effective retrieval. -->
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# 🎖 Honors and Awards
<!--- *2023.10*, Outstanding Freshman Scholarship of Wuhan University-->
- *2020.09 - 2023.06*, Advanced Individual of Wuhan University (3 times)
- *2020.09 - 2023.06*, Outstanding Student Scholarship of Wuhan University (3 times)

# 📖 Educations
- *2023.09 - 2026.06 (now)*, Master, Wuhan University, Wuhan.
- *2019.09 - 2023.06*, Undergraduate, Wuhan University, Wuhan.

# 💻 Internships
- *2024.05 - 2024.09*, TeleAI, China,Beijing.
